import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from xgboost import XGBClassifier
from geneticalgorithm import geneticalgorithm as ga
import joblib
import sqlite3
import os
from sklearn.preprocessing import LabelEncoder

# ---------------------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ----------------------
st.set_page_config(page_title="Ù…Ø´Ø§ÙˆØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú©Ù†Ú©ÙˆØ±", layout="wide")
st.title("ğŸ“ Ù…Ø´Ø§ÙˆØ± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ú©Ù†Ú©ÙˆØ± - Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±ÛŒØ²ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù")

# ---------------------- ØªÙˆÙ„ÛŒØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ ----------------------
def generate_sample_data():
    data = {
        "lesson": ["Ø±ÛŒØ§Ø¶ÛŒ", "ÙÛŒØ²ÛŒÚ©", "Ø´ÛŒÙ…ÛŒ", "Ø§Ø¯Ø¨ÛŒØ§Øª", "Ø²Ø¨Ø§Ù†"],
        "topic": ["ØªØ§Ø¨Ø¹", "Ø³ÛŒÙ†Ù…Ø§ØªÛŒÚ©", "Ø§Ø³ØªÙˆÚ©ÛŒÙˆÙ…ØªØ±ÛŒ", "Ø§Ù…Ù„Ø§", "Ú¯Ø±Ø§Ù…Ø±"],
        "score": [12, 14, 18, 16, 15],
        "difficulty": [4, 5, 3, 2, 2]
    }
    return pd.DataFrame(data)

# ---------------------- Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ ØªØ´Ø®ÛŒØµ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù ----------------------
def train_weakness_detector(data, threshold=15):
    # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    le = LabelEncoder()
    
    # Ø§Ú¯Ø± encoder Ù‚Ø¯ÛŒÙ…ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø¢Ù† Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†
    if os.path.exists('label_encoder.pkl'):
        existing_le = joblib.load('label_encoder.pkl')
        le.classes_ = existing_le.classes_
    
    data['lesson_code'] = le.fit_transform(data['lesson'])
    
    # Ø°Ø®ÛŒØ±Ù‡ encoder
    joblib.dump(le, 'label_encoder.pkl')
    
    features = data[['score', 'difficulty', 'lesson_code']]
    
    # Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¨Ø§ Ø¢Ø³ØªØ§Ù†Ù‡ Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ…
    data['Ø¶Ø¹Ù'] = (data['score'] < threshold).astype(int)
    
    # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    model = XGBClassifier()
    model.fit(features, data['Ø¶Ø¹Ù'])
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ùˆ Ù†Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
    joblib.dump(model, 'weakness_model.pkl')
    joblib.dump(features.columns.tolist(), 'feature_names.pkl')
    return model

# ---------------------- Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…Ø·Ø§Ù„Ø¹Ø§ØªÛŒ ----------------------
def optimize_study_plan(weakness_scores, difficulties, total_hours=20):
    # ØªØ§Ø¨Ø¹ Ù‡Ø¯Ù Ø¨Ø§ Ù¾Ù†Ø§Ù„ØªÛŒ
    def objective(x):
        main_score = -np.sum(weakness_scores * difficulties * x)
        penalty = 1000 * abs(np.sum(x) - total_hours)
        return main_score + penalty

    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…
    varbounds = np.array([[0.1, total_hours]] * len(weakness_scores))
    
    algorithm_param = {
        'max_num_iteration': 200,
        'population_size': 100,
        'mutation_probability': 0.1,
        'elit_ratio': 0.1,
        'crossover_probability': 0.5,
        'crossover_type': 'uniform',  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±
        'parents_portion': 0.3,
        'max_iteration_without_improv': 50
    }
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„
    model = ga(
        function=objective,
        dimension=len(weakness_scores),
        variable_type='real',
        variable_boundaries=varbounds,
        algorithm_parameters=algorithm_param
    )
    
    model.run()
    
    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù†ØªØ§ÛŒØ¬
    optimized_hours = model.output_dict['variable']
    optimized_hours = optimized_hours * (total_hours / np.sum(optimized_hours))
    
    return np.round(optimized_hours, 1)

# ---------------------- Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Streamlit ----------------------
def main():
    # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯
    if not os.path.exists('label_encoder.pkl') or not os.path.exists('weakness_model.pkl'):
        st.warning("ğŸ”§ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø³ÛŒØ³ØªÙ…...")
        df_sample = generate_sample_data()
        train_weakness_detector(df_sample)
        st.experimental_rerun()

    # Ø¨Ø®Ø´ Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    st.sidebar.header("ğŸ“¤ ÙˆØ±ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯")
    with st.sidebar.form("ÙˆØ±ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"):
        lesson = st.text_input("Ù†Ø§Ù… Ø¯Ø±Ø³")
        topic = st.text_input("Ù…Ø¨Ø­Ø«")
        score = st.number_input("Ù†Ù…Ø±Ù‡ Ø¢Ø²Ù…ÙˆÙ†", 0, 20)
        difficulty = st.slider("Ø³Ø®ØªÛŒ Ù…Ø¨Ø­Ø«", 1, 5)
        threshold = st.slider("Ø¢Ø³ØªØ§Ù†Ù‡ ØªØ´Ø®ÛŒØµ Ø¶Ø¹Ù", 0, 20, 15)
        
        if st.form_submit_button("Ø°Ø®ÛŒØ±Ù‡"):
            c.execute("INSERT INTO scores VALUES (?, ?, ?, ?)", 
                     (lesson, topic, score, difficulty))
            conn.commit()
            st.success("âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯!")

    # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    st.sidebar.header("ğŸ›  Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„")
    if st.sidebar.button("Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯"):
        df = pd.read_sql("SELECT * FROM scores", conn)
        if len(df) > 0:
            try:
                train_weakness_detector(df, threshold)
                st.sidebar.success("ğŸ‰ Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯!")
            except Exception as e:
                st.sidebar.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„: {str(e)}")
        else:
            st.sidebar.warning("âš ï¸ Ø§Ø¨ØªØ¯Ø§ Ø¯Ø§Ø¯Ù‡ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯!")

    # Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
    st.subheader("ğŸ“Š Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡")
    df = pd.read_sql("SELECT * FROM scores", conn)
    st.dataframe(df)

    # ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    if not df.empty:
        try:
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ encoder
            le = joblib.load('label_encoder.pkl')
            model = joblib.load('weakness_model.pkl')
            feature_names = joblib.load('feature_names.pkl')
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
            current_lessons = set(df['lesson'].unique())
            trained_lessons = set(le.classes_)
            
            if not current_lessons.issubset(trained_lessons):
                st.warning("âš ï¸ Ø¯Ø±Ø³â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡! Ù„Ø·ÙØ§Ù‹ Ù…Ø¯Ù„ Ø±Ø§ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯.")
                return
            
            # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            df['lesson_code'] = le.transform(df['lesson'])
            features = df[feature_names]
            
            # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
            df['Ø¶Ø¹Ù'] = model.predict(features)
            
            # Ù†Ù…Ø§ÛŒØ´ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ
            col1, col2 = st.columns(2)
            with col1:
                st.subheader("ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ù†Ù‚Ø§Ø· Ø¶Ø¹Ù")
                fig = px.bar(df, x='topic', y='score', color='lesson', 
                            title='Ù†Ù…Ø±Ø§Øª Ø¢Ø²Ù…ÙˆÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¨Ø­Ø«')
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.subheader("ğŸ“š Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø·Ø§Ù„Ø¹Ø§ØªÛŒ")
                for idx, row in df[df['Ø¶Ø¹Ù'] == 1].iterrows():
                    st.markdown(f"""
                    ğŸ§© **Ù…Ø¨Ø­Ø« {row['topic']} ({row['lesson']})**  
                    ğŸ“š Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©ØªØ§Ø¨: Ú©ØªØ§Ø¨ Ø¬Ø§Ù…Ø¹ Ú©Ù†Ú©ÙˆØ± {row['lesson']} Ø§Ù†ØªØ´Ø§Ø±Ø§Øª Ø®ÛŒÙ„ÛŒ Ø³Ø¨Ø²  
                    ğŸ¥ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ: [ÙÛŒÙ„Ù… Ø¢Ù…ÙˆØ²Ø´ {row['topic']}](https://example.com)
                    """)
            
            # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù…Ø·Ø§Ù„Ø¹Ø§ØªÛŒ
            st.subheader("ğŸ¯ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø±ÛŒØ²ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù‡ÙØªÚ¯ÛŒ")
            total_hours = st.slider("â° Ú©Ù„ Ø³Ø§Ø¹Ø§Øª Ù…Ø·Ø§Ù„Ø¹Ù‡ Ù‡ÙØªÚ¯ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±:", 10, 40, 20)
            
            if st.button("ğŸ”„ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡"):
                weakness_scores = df['Ø¶Ø¹Ù'].values
                difficulties = df['difficulty'].values
                
                try:
                    optimized_hours = optimize_study_plan(weakness_scores, difficulties, total_hours)
                    optimized_hours = optimized_hours * (total_hours / np.sum(optimized_hours))
                    optimized_hours = np.round(optimized_hours, 1)
                    
                    df['Ø²Ù…Ø§Ù†_Ø¨Ù‡ÛŒÙ†Ù‡'] = optimized_hours
                    df['Ø§ÙˆÙ„ÙˆÛŒØª'] = df['Ø¶Ø¹Ù'] * df['difficulty']
                    df = df.sort_values('Ø§ÙˆÙ„ÙˆÛŒØª', ascending=False)
                    
                    st.success("âœ… Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ:")
                    for idx, row in df.iterrows():
                        st.markdown(f"""
                        **{row['lesson']} ({row['topic']})**  
                        â³ Ø²Ù…Ø§Ù† Ù…Ø·Ø§Ù„Ø¹Ù‡: {row['Ø²Ù…Ø§Ù†_Ø¨Ù‡ÛŒÙ†Ù‡']} Ø³Ø§Ø¹Øª  
                        ğŸ¯ Ø³Ø·Ø­ Ø§ÙˆÙ„ÙˆÛŒØª: {row['Ø§ÙˆÙ„ÙˆÛŒØª']}/20  
                        ğŸ” ÙˆØ¶Ø¹ÛŒØª: {"Ø¶Ø¹ÛŒÙ - Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ…Ø±Ú©Ø² Ø¨ÛŒØ´ØªØ±" if row['Ø¶Ø¹Ù'] else "Ù‚ÙˆÛŒ - Ù…Ø±ÙˆØ± Ø³Ø±ÛŒØ¹"}
                        """)
                except Exception as e:
                    st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: {str(e)}")
                    
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„: {str(e)}")
            return

# ---------------------- Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ----------------------
conn = sqlite3.connect('student_data.db', check_same_thread=False)
c = conn.cursor()

# Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
c.execute('''
    CREATE TABLE IF NOT EXISTS scores (
        lesson TEXT,
        topic TEXT,
        score INTEGER,
        difficulty INTEGER
    )
''')
conn.commit()

if __name__ == "__main__":
    main()
